---
title: "Why and how to approach reproducibility"
date: 2025-04-28
date-format: YYYY-MM-DD
format:
  html:
    toc: true
    toc-expand: 2
---

Reproducible research makes all elements of the research project available for others openly so that the project can be reproduced. Specifically, it means that the [research compendium](https://book.the-turing-way.org/reproducible-research/compendia), which are these elements assembled together in a logical and clear fashion, are published alongside the research paper. The practice creating and publishing a research compendium may involve some technical skills, however it will help the research team leading the project, other researchers, and the discipline as a whole. It will also help publish official statistics with the methods being researched, as the Reproducible Analytical Pipelines (RAP) principles applied to reproducible and technically mature production processes leverage the very same technical best practices. Indeed, RAP and research compedia are conceptually the same things â€“ the application of technical processes for reproducibility and process robustness -- its just one focuses more on research and the other on production of official statistics.

## Structuring the research compendium

In a nutshell, a compendium includes all research objects necessary to reproduce the research. In a technical sense, these are often git repositories (in say GitHub) that include a structure similar to the one in Figure 1 below.

![Figure 1: Exemplar [price index pipeline](https://github.com/UN-Task-Team-for-Scanner-Data/price-index-pipeline).](/docs/images/price-stats-exemplar.svg)

Specifically:

-   A data folder stores the raw dataset used for the research project. Ideally the researcher uses an open dataset (which will make the whole process reproducible), but they may also use a proprietary dataset. Note the dataset itself should not be version controlled with the repository but the ability to save the dataset in this folder means that others can download the repository, save the dataset in the same folder, and replicate the results. In a technical sense, the data itself is ignored by making sure that it is listed in the `.gitignore` file.
-   A functions (or code) folder that does the research aspects. This could include the code to clean and prepare the raw dataset for research purposes, the code to create the processing and research experients, as well as notebooks where the data is explored and various aspects that feed the research paper are generated.
-   A folder for the output data. This data can be versioned (if it is not sensitive) with the repository and allows researchers to replicate the process. Note, if the output data can be used for research in its own right, it may be appropriate to register this dataset on a public repository (such as Zenodo) that mints a DOI.
-   A folder for the docs that explain how the various aspects of the research come together. This folder stores [project documentation](https://book.the-turing-way.org/reproducible-research/code-documentation/code-documentation-project) or [the project design](https://book.the-turing-way.org/project-design/pd-overview), however [code should also be documented](https://book.the-turing-way.org/reproducible-research/code-documentation/code-documentation-code) well.
-   A licence is included to tell users how they can use the code.
-   `.gitignore` file ignores various files (such as datasets) from being version controlled
-   A file to [recreate the environment](https://book.the-turing-way.org/reproducible-research/renv) so that the code can be run as it ran on the machine of the researcher.
-   Finally, a README to introduce the project when someone navigates to the project

To showcase an exemplar for price statistics, we created [a mock-up price index pipeline](https://github.com/UN-Task-Team-for-Scanner-Data/price-index-pipeline) that researchers can explore.